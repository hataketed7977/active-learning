- #Temperature
	- 范围：0 - 1
	- 用于控制生成文本时的随机性，影响采样过程
		- 参数值越小，模型就会返回越确定的一个结果 (选择最可能的词汇)
		- 参数值越大，模型就会返回更随机的结果 (创意和多样化)
- #Top_p
	- 范围：0 - 1
	- 控制模型返回结果的真实性（从累积概率超过该阈值的最小令牌集中进行选择）
		- 如果你需要准确和事实的答案，就把参数值调低。
		- 如果你想要更多样化的答案，就把参数值调高一些。
-
- **组合效果：** #Temperature 和 #Top-p 可以一起使用，实现在随机性和连贯性之间的平衡。
	- 高 #Temperature 与高 #Top-p ：更多随机性和多样性。
	- 低 #Temperature 与低 #Top-p ：更为集中和确定性的输出。
- 总体而言，温度控制整体的随机性，而Top-p影响文本生成过程中所选择词汇的多样性。通过调整这些参数，可以微调生成文本中创造性和连贯性之间的平衡。
	- 最佳值取决于具体应用场景，通常需要通过实验找到最适合生成文本特性的参数组合。
-
- #MaxLength
	- GPT-3 范围：1 - 4096 个“标记”（token）
		- 一个 token 可以是一个单词、一个短语、甚至是一个句子。字符是文本的基本单位。
	- 管理模型生成的标记数量，指定最大长度有助于您防止过长或不相关的响应并控制成本。
		- 可以从较小的值开始，然后根据实际情况进行调整。
		- 可以根据生成文本的任务来确定 max length 的范围。
		- 可以使用不同的 max length 来生成不同的版本的文本，然后进行比较，选择最合适的版本。
	- #上下文感知
		- Transformer的神经网络架构来实现
			- 在对话中，每一轮的输入都被编码为向量表示，并且这些向量在模型的注意力机制中被用于推断对话上下文。在模型的训练过程中，通过调整参数来最小化损失函数，使得模型能够逐渐学到正确地捕捉上下文信息。
		- 虽然大部分LLM不会限制输入的长度，但是上下文感知大小是有限的，它由我所接受训练的数据集的大小决定。如果主题太广泛或太复杂，或者轮数太多，可能无法跟踪所有上下文信息。
-
- #Stop-Sequences
	- 一个或多个字符的字符串。
	- 一个停止模型生成标记的字符串，控制模型响应长度和结构的另一种方法。
		- 如果指定了 #Stop-Sequence ，那么在您指定的其中一个 #Stop-Sequence 出现在生成的输出中之后，模型将自动停止生成输出
			- 例如：
				- **控制输出长度**：使用 #Stop-Sequence 可以控制生成输出的长度。例如，如果您希望模型仅生成一个句子，那么您可以将句点指定为 #Stop-Sequence
				- **生成特定格式的输出**：使用 #Stop-Sequence 可以生成特定格式的输出。例如，如果您希望模型生成一个诗歌，那么您可以将空格指定为 #Stop-Sequence
				- **防止模型生成不想要的输出**：使用 #Stop-Sequence 可以防止模型生成不想要的输出。例如，如果您希望模型生成一个新闻文章，那么您可以将敏感词指定为 #Stop-Sequence
		- ```python
		  # 在调用生成方法时传递Stop Sequence 作为参数。
		  
		  response = model.generate(prompt="The quick brown fox jumps over the lazy dog.", stop_sequences=["."])
		  
		  # 在模型的配置中设置Stop Sequence。
		  
		  model.config.stop_sequences = ["."]
		  ```
-
-
- #Frequency-Penalty 频率惩罚
	- 范围：-2.0 - 2.0 (默认0)
		- 设置为 0.0 时，模型将生成不受频率影响的输出。这意味着模型可能会生成重复的文本，但也可能会生成新颖和有创意的文本。
		- 设置为 1.0 时，模型将更有可能生成不那么常见的词。这意味着模型生成的输出将更具多样性，但也可能不那么准确或相关。
		- 设置为 2.0 时，模型将更有可能生成非常不常见的词。这意味着模型生成的输出将非常多样化，但也可能非常不准确或不相关。
	- 对下一个标记应用惩罚，频率惩罚越高，某个词再次出现的可能性就越小。
		- 是一种用于调整生成文本多样性的技术。
		- 一种全局性的机制，作用于整个生成过程。
		- 以减少高频词汇的使用，从而提高文本的多样性。
		- 例如：
			- **增加文本多样性：** 通过对高频词汇应用惩罚，可以促使模型生成更加多样化、不那么重复的文本。这对于提高生成文本的吸引力和自然度非常有帮助。
			- **控制特定词汇的出现：** 在一些特定场景中，可能希望限制或增加某些特定词汇的出现频率。通过调整频率惩罚参数，可以在生成文本时实现对特定词汇的控制。
			- **自定义生成文本的特性：** 频率惩罚是调整生成文本风格和特性的一种方式。它可以用来确保生成的文本符合特定的要求，例如在文学创作、广告文案等领域。
		- ```python
		  
		  import transformers
		  
		  # 加载模型
		  model = transformers.AutoModelForCausalLM.from_pretrained("path/to/model")
		  
		  # 设置 Frequency Penalty
		  model.config.frequency_penalty = 0.5
		  
		  # 生成文本
		  response = model.generate(prompt="The quick brown fox jumps over the lazy dog.")
		  
		  print(response)
		  
		  ```
-
- #Presence-Penalty 存在惩罚
	- 减少生成文本中某些指定词语或短语的出现。与频率惩罚类似，存在惩罚的目的是调整生成文本中词汇的分布，以实现更多样化的结果。
	- based on if they have ocurred or not, instead of proportionally.
	- 一般建议是更改频率或存在惩罚，而不是同时更改两者。
	-
-